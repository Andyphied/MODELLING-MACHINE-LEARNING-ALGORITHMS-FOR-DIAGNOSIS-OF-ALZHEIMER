{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.model_selection import (RandomizedSearchCV, GridSearchCV)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dat = pd.read_csv('Standardized_ALz_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>3.730000e+02</td>\n",
       "      <td>3.730000e+02</td>\n",
       "      <td>3.730000e+02</td>\n",
       "      <td>3.730000e+02</td>\n",
       "      <td>3.730000e+02</td>\n",
       "      <td>3.730000e+02</td>\n",
       "      <td>3.730000e+02</td>\n",
       "      <td>3.730000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.490617</td>\n",
       "      <td>-1.089388e-16</td>\n",
       "      <td>-4.161104e-16</td>\n",
       "      <td>-3.625340e-16</td>\n",
       "      <td>-2.047811e-16</td>\n",
       "      <td>-2.047811e-16</td>\n",
       "      <td>8.125761e-17</td>\n",
       "      <td>-3.928939e-16</td>\n",
       "      <td>8.890714e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.500583</td>\n",
       "      <td>1.001343e+00</td>\n",
       "      <td>1.001343e+00</td>\n",
       "      <td>1.001343e+00</td>\n",
       "      <td>1.001343e+00</td>\n",
       "      <td>1.001343e+00</td>\n",
       "      <td>1.001343e+00</td>\n",
       "      <td>1.001343e+00</td>\n",
       "      <td>1.001343e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.667028e-01</td>\n",
       "      <td>-2.229597e+00</td>\n",
       "      <td>-2.993181e+00</td>\n",
       "      <td>-1.297140e+00</td>\n",
       "      <td>-1.297140e+00</td>\n",
       "      <td>-2.172383e+00</td>\n",
       "      <td>-2.307345e+00</td>\n",
       "      <td>-2.316501e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.667028e-01</td>\n",
       "      <td>-7.880533e-01</td>\n",
       "      <td>-9.043942e-01</td>\n",
       "      <td>-3.944662e-01</td>\n",
       "      <td>-3.944662e-01</td>\n",
       "      <td>-7.454601e-01</td>\n",
       "      <td>-7.973089e-01</td>\n",
       "      <td>-6.994664e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.667028e-01</td>\n",
       "      <td>-1.756695e-03</td>\n",
       "      <td>1.399991e-01</td>\n",
       "      <td>-3.944662e-01</td>\n",
       "      <td>-3.944662e-01</td>\n",
       "      <td>-1.030607e-01</td>\n",
       "      <td>-1.532591e-02</td>\n",
       "      <td>-1.059503e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.153798e+00</td>\n",
       "      <td>6.534905e-01</td>\n",
       "      <td>4.881302e-01</td>\n",
       "      <td>5.082080e-01</td>\n",
       "      <td>5.082080e-01</td>\n",
       "      <td>6.189281e-01</td>\n",
       "      <td>7.127272e-01</td>\n",
       "      <td>7.072815e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.153798e+00</td>\n",
       "      <td>2.750282e+00</td>\n",
       "      <td>2.925048e+00</td>\n",
       "      <td>2.313556e+00</td>\n",
       "      <td>2.313556e+00</td>\n",
       "      <td>2.932703e+00</td>\n",
       "      <td>2.896887e+00</td>\n",
       "      <td>2.839157e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Group           M/F           Age          EDUC           SES  \\\n",
       "count  373.000000  3.730000e+02  3.730000e+02  3.730000e+02  3.730000e+02   \n",
       "mean     0.490617 -1.089388e-16 -4.161104e-16 -3.625340e-16 -2.047811e-16   \n",
       "std      0.500583  1.001343e+00  1.001343e+00  1.001343e+00  1.001343e+00   \n",
       "min      0.000000 -8.667028e-01 -2.229597e+00 -2.993181e+00 -1.297140e+00   \n",
       "25%      0.000000 -8.667028e-01 -7.880533e-01 -9.043942e-01 -3.944662e-01   \n",
       "50%      0.000000 -8.667028e-01 -1.756695e-03  1.399991e-01 -3.944662e-01   \n",
       "75%      1.000000  1.153798e+00  6.534905e-01  4.881302e-01  5.082080e-01   \n",
       "max      1.000000  1.153798e+00  2.750282e+00  2.925048e+00  2.313556e+00   \n",
       "\n",
       "               MMSE          eTIV          nWBV           ASF  \n",
       "count  3.730000e+02  3.730000e+02  3.730000e+02  3.730000e+02  \n",
       "mean  -2.047811e-16  8.125761e-17 -3.928939e-16  8.890714e-16  \n",
       "std    1.001343e+00  1.001343e+00  1.001343e+00  1.001343e+00  \n",
       "min   -1.297140e+00 -2.172383e+00 -2.307345e+00 -2.316501e+00  \n",
       "25%   -3.944662e-01 -7.454601e-01 -7.973089e-01 -6.994664e-01  \n",
       "50%   -3.944662e-01 -1.030607e-01 -1.532591e-02 -1.059503e-02  \n",
       "75%    5.082080e-01  6.189281e-01  7.127272e-01  7.072815e-01  \n",
       "max    2.313556e+00  2.932703e+00  2.896887e+00  2.839157e+00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_dat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01 = mod_dat.copy()\n",
    "feature_df = train_01.drop([\"Group\"],axis=1)\n",
    "feature_df2 = train_01[\"Group\"].values\n",
    "x = np.asarray(feature_df)\n",
    "y = np.asarray(feature_df2)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.89% Train\n",
      "20.11% Test\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:0.2f}% Train\".format((len(x_train)/len(train_01.index)) * 100))\n",
    "print(\"{0:0.2f}% Test\".format((len(x_test)/len(train_01.index)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Demented : 183 (49.06%)\n",
      "Original Nondemented : 190 (50.94%)\n",
      "\n",
      "Training Demented : 142 (47.65%)\n",
      "Training Nondemented : 156 (52.35%)\n",
      "\n",
      "Test Demented : 41 (54.67%)\n",
      "Test Nondemented : 34 (45.33%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Demented : {0} ({1:0.2f}%)\".format(len(train_01.loc[train_01['Group'] == 1]), 100 * (len(train_01.loc[train_01['Group'] == 1]) / len(train_01))))\n",
    "print(\"Original Nondemented : {0} ({1:0.2f}%)\".format(len(train_01.loc[train_01['Group'] == 0]), 100 * (len(train_01.loc[train_01['Group'] == 0]) / len(train_01))))\n",
    "print(\"\")\n",
    "print(\"Training Demented : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 1]), 100 * (len(y_train[y_train[:] == 1]) / len(y_train))))\n",
    "print(\"Training Nondemented : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 0]), 100 * (len(y_train[y_train[:] == 0]) / len(y_train))))\n",
    "print(\"\")\n",
    "print(\"Test Demented : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 1]), 100 * (len(y_test[y_test[:] == 1]) / len(y_test))))\n",
    "print(\"Test Nondemented : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 0]), 100 * (len(y_test[y_test[:] == 0]) / len(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "Best Params {'C': 0.4747579797979798, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Score 0.6778523489932886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:    5.1s finished\n"
     ]
    }
   ],
   "source": [
    "#Tunning All hyperparameters using the difffrent methods\n",
    "#Logistic Regression\n",
    "penalty = ['l1', 'l2'] # l1 is Lasso, l2 is Ridge\n",
    "solver= ['liblinear']\n",
    "samplec = np.linspace(0.00002,1,100)\n",
    "\n",
    "params = {\n",
    "    'penalty':penalty,        \n",
    "    'solver':solver,\n",
    "    'C': samplec\n",
    "}\n",
    "\n",
    "linear_reg = LogisticRegression()\n",
    "linear_gs = GridSearchCV(linear_reg, params, cv=3, verbose=1)\n",
    "linear_gs.fit(x_train, y_train)\n",
    "\n",
    "print (\"Best Params\", linear_gs.best_params_)\n",
    "print (\"Best Score\", linear_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:   56.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.5525267499052782\n"
     ]
    }
   ],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create randomized search 5-fold cross validation and 100 iteration\n",
    "rscv = RandomizedSearchCV(linear_reg, hyperparameters, random_state=19, n_iter=1000, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit randomized search\n",
    "best_model = rscv.fit(x_train, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6644295302013423"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1981 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3277 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed: 46.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4897 tasks      | elapsed: 56.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5828 tasks      | elapsed: 66.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6841 tasks      | elapsed: 78.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7934 tasks      | elapsed: 91.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9109 tasks      | elapsed: 104.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 114.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'n_estimators': 128, 'min_samples_split': 3, 'max_features': 'sqrt', 'max_depth': 31}\n",
      "Best Score 0.8850850910834134\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = range(10,250)\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = range(1,40)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = range(3,60)\n",
    "\n",
    "# Create the random grid\n",
    "parametro_rf = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split}\n",
    "\n",
    "model_forest = RandomForestClassifier(n_jobs=-1)\n",
    "forest_random = RandomizedSearchCV(estimator = model_forest, param_distributions = parametro_rf, n_iter = 1000, cv = 10, \n",
    "                               verbose=2, random_state=19, n_jobs = -1, scoring='roc_auc')\n",
    "forest_random.fit(x_train, y_train)\n",
    "\n",
    "print (\"Best Params\", forest_random.best_params_)\n",
    "print (\"Best Score\", forest_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1981 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3277 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4897 tasks      | elapsed: 61.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5828 tasks      | elapsed: 70.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6841 tasks      | elapsed: 81.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7934 tasks      | elapsed: 92.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9109 tasks      | elapsed: 104.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 112.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=1000, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': range(10, 250), 'max_features': ['auto', 'sqrt'], 'max_depth': range(1, 40), 'min_samples_split': range(3, 60)},\n",
       "          pre_dispatch='2*n_jobs', random_state=19, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trees in Extra Trees\n",
    "n_estimators = range(50,280)\n",
    "# Maximum number of levels in tree\n",
    "max_depth =  range(1,40)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_leaf = [3,4,5,6,7,8,9,10,15,20,30,40,50,60]\n",
    "# Create the random grid\n",
    "parametro_Et = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "model_et = ExtraTreesClassifier(n_jobs=-1)\n",
    "et_random = RandomizedSearchCV(estimator = model_et, param_distributions = parametro_rf, n_iter = 1000, cv = 10, \n",
    "                               verbose=2, random_state=19, n_jobs = -1, scoring='roc_auc')\n",
    "et_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'n_estimators': 241, 'min_samples_split': 3, 'max_features': 'auto', 'max_depth': 23}\n",
      "Best Score 0.9240961569191434\n"
     ]
    }
   ],
   "source": [
    "print (\"Best Params\", et_random.best_params_)\n",
    "print (\"Best Score\", et_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1981 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3277 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed: 43.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4897 tasks      | elapsed: 50.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5828 tasks      | elapsed: 58.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6841 tasks      | elapsed: 67.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7934 tasks      | elapsed: 77.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9109 tasks      | elapsed: 88.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 95.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'n_estimators': 71, 'learning_rate': 1}\n",
      "Best Score 0.7682146852029402\n"
     ]
    }
   ],
   "source": [
    "#Optimizing Adabosst Classifier\n",
    "\n",
    "n_estimators = range(10,200)\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1,0.2,0.3,0.4\n",
    ",0.5,0.6,0.7,0.8,0.9,0.95,1]\n",
    "\n",
    "# Create the random grid\n",
    "parametros_ada = {'n_estimators': n_estimators,'learning_rate': learning_rate}\n",
    "\n",
    "model_ada = AdaBoostClassifier()\n",
    "ada_random = RandomizedSearchCV(estimator = model_ada, param_distributions = parametros_ada, n_iter = 1000,cv = 10, \n",
    "                                verbose=2, random_state=19, n_jobs = -1, scoring='roc_auc')\n",
    "\n",
    "ada_random.fit(x_train, y_train)\n",
    "print (\"Best Params\", ada_random.best_params_)\n",
    "print (\"Best Score\", ada_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 288 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   55.5s\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1212 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1917 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 out of 2880 | elapsed: 161.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Best Score 0.9164789069990411\n"
     ]
    }
   ],
   "source": [
    "#Svm Classifer Optimization of parameters\n",
    "C = [0.001, 0.10, 0.1, 10, 25, 50,65,70,80,90, 100, 1000]\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "gamma =[1e-2, 1e-3, 1e-4, 1e-5,1e-6,1]\n",
    "\n",
    "# Create the grid search\n",
    "parametros_svm = {'C': C,\n",
    "                  'gamma': gamma,\n",
    "                  'kernel': kernel}\n",
    "\n",
    "model_svm = SVC()\n",
    "\n",
    "svm_random = GridSearchCV(model_svm, parametros_svm, cv = 10, verbose=2,\n",
    "                          n_jobs = -1, scoring='roc_auc' )\n",
    "svm_random.fit(x_train, y_train)\n",
    "print (\"Best Params\", svm_random.best_params_)\n",
    "print (\"Best Score\", svm_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 997 out of 1000 | elapsed:  3.4min remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'loss': ['deviance'], 'learning_rate': [0.01, 0.025, 0.005, 0.5, 0.075, 0.1, 0.15, 0.2, 0.3, 0.8, 0.9], 'min_samples_split': [0.01, 0.025, 0.005, 0.4, 0.5, 0.075, 0.1, 0.15, 0.2, 0.3, 0.8, 0.9], 'min_samples_leaf': [1, 2, 3, 5, 8, 10, 15, 20, 40, 50, 55, 60, 65, 70, 80, 85, 90, ...n_mse', 'mae'], 'subsample': [0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0], 'n_estimators': range(1, 100)},\n",
       "          pre_dispatch='2*n_jobs', random_state=19, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4Â° Gradient Boosting\n",
    "\n",
    "parametros_gb = {\"loss\":[\"deviance\"],\"learning_rate\": [0.01, 0.025, 0.005,0.5, 0.075,0.1, 0.15, 0.2,0.3,0.8,0.9],\n",
    "                 \"min_samples_split\": [0.01, 0.025, 0.005,0.4,0.5,0.075, 0.1, 0.15, 0.2,0.3,0.8,0.9],\n",
    "                 \"min_samples_leaf\": [1,2,3,5,8,10,15,20,40,50,55,60,65,70,80,85,90,100],\n",
    "                 \"max_depth\":[3,5,8,10,15,20,25,30,40,50],\"max_features\":[\"log2\",\"sqrt\"],\n",
    "                 \"criterion\": [\"friedman_mse\", \"mae\"],\"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "                 \"n_estimators\":range(1,100)}\n",
    "\n",
    "model_gb= GradientBoostingClassifier()\n",
    "gb_random = RandomizedSearchCV(estimator = model_gb,param_distributions = parametros_gb, n_iter = 100, cv= 10,\n",
    "                               verbose=2, random_state=19, n_jobs = -1, scoring='roc_auc')\n",
    "gb_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'subsample': 0.8, 'n_estimators': 51, 'min_samples_split': 0.005, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 8, 'loss': 'deviance', 'learning_rate': 0.025, 'criterion': 'friedman_mse'}\n",
      "Best Score 0.88592401725791\n"
     ]
    }
   ],
   "source": [
    "print (\"Best Params\", gb_random.best_params_)\n",
    "print (\"Best Score\", gb_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-67e958254fbe>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-67e958254fbe>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    knn_pram {'n_neighbors': 1, 'metric': 'cityblock'}\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "log_reg_param = {'C': 0.4747579797979798, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "rand_for_pram ={'n_estimators': 128, 'min_samples_split': 3, 'max_features': 'sqrt', 'max_depth': 31}\n",
    "extr_tre_pram ={'n_estimators': 241, 'min_samples_split': 3, 'max_features': 'auto', 'max_depth': 23}\n",
    "ada_bost_pram = {'n_estimators': 71, 'learning_rate': 1}\n",
    "svm_pram ={'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
    "gb_pram = {'subsample': 0.8, 'n_estimators': 51, 'min_samples_split': 0.005, 'min_samples_leaf': 1, 'max_features': 'sqrt', \n",
    "           'max_depth': 8, 'loss': 'deviance', 'learning_rate': 0.025, 'criterion': 'friedman_mse'}\n",
    "knn_pram {'n_neighbors': 1, 'metric': 'cityblock'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators= 128, min_samples_split= 3, max_features= 'sqrt', max_depth = 31)\n",
    "et_model = ExtraTreesClassifier(n_estimators= 241, min_samples_split= 3, max_features= 'auto', max_depth = 23)\n",
    "av_model = AdaBoostClassifier(n_estimators = 71, learning_rate = 0.8)\n",
    "svm_model = SVC(C= 10, gamma = 1, kernel = 'rbf')\n",
    "gb_model = GradientBoostingClassifier(subsample = 0.8, n_estimators = 51, min_samples_split = 0.005, min_samples_leaf = 1, \n",
    "                                      max_features = 'sqrt', max_depth = 8, loss = 'deviance', learning_rate = 0.025, \n",
    "                                      criterion = 'friedman_mse')\n",
    "gnb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=31, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=128,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  5]\n",
      " [ 4 37]]\n",
      "Train accuracy: 100.00%\n",
      "Test accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rf_y_pred))\n",
    "w = rf_model.score(x_train, y_train)\n",
    "v = rf_model.score(x_test, y_test)\n",
    "print(f\"Train accuracy: {w:0.2%}\")\n",
    "print(f\"Test accuracy: {v:0.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(x_train, y_train)\n",
    "et_model.fit(x_train, y_train)\n",
    "av_model.fit(x_train, y_train)\n",
    "svm_model.fit(x_train, y_train)\n",
    "gb_model.fit(x_train, y_train)\n",
    "gnb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   23.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_neighbors': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33,\n",
       "       35, 37, 39]), 'metric': ['euclidean', 'cityblock'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
       "          pre_dispatch='2*n_jobs', random_state=19, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_params = {\"n_neighbors\": np.arange(1, 41, 2),\"metric\": [\"euclidean\", \"cityblock\"],\n",
    "              \"algorithm\" : ['auto', 'ball_tree', 'kd_tree', 'brute'] }\n",
    "model_knn= KNeighborsClassifier()\n",
    "knn_random = RandomizedSearchCV(estimator = model_knn,param_distributions = knn_params, n_iter = 100, cv= 10,\n",
    "                               verbose=2, random_state=19, n_jobs = -1, scoring='roc_auc')\n",
    "knn_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'n_neighbors': 1, 'metric': 'cityblock', 'algorithm': 'auto'}\n",
      "Best Score 0.8901096596356665\n"
     ]
    }
   ],
   "source": [
    "print (\"Best Params\", knn_random.best_params_)\n",
    "print (\"Best Score\", knn_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best Params {'n_neighbors': 1, 'metric': 'cityblock'}\n",
      "Best Score 0.8901096596356665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    7.2s finished\n"
     ]
    }
   ],
   "source": [
    "knn_gs = GridSearchCV(model_knn, knn_params, cv=10, verbose=1)\n",
    "knn_gs.fit(x_train, y_train)\n",
    "print (\"Best Params\", knn_random.best_params_)\n",
    "print (\"Best Score\", knn_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='cityblock',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors = 1, metric = 'cityblock', algorithm  = 'auto')\n",
    "knn_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(16, 14, 9, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=100000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=19, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building Of ANN Model\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    " \n",
    "\n",
    "\n",
    "ann_model = MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "                       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "                       hidden_layer_sizes=(16,14,9,2), learning_rate='constant',\n",
    "                       learning_rate_init=0.001, max_iter=100000, momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
    "                       random_state=19, shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "ann_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_y_pred = ann_model.predict(x_test)\n",
    "et_y_pred = et_model.predict(x_test)\n",
    "av_y_pred = av_model.predict(x_test)\n",
    "svm_y_pred = svm_model.predict(x_test)\n",
    "gb_y_pred = gb_model.predict(x_test)\n",
    "gnb_y_pred = gnb_model.predict(x_test)\n",
    "rf_y_pred = rf_model.predict(x_test)\n",
    "knn_y_pred = knn_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc, f1_score\n",
    "def accuracy(x_test, y_test, x_train, y_train, model):\n",
    "    print(model.__class__)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    w = model.score(x_train, y_train)\n",
    "    v = model.score(x_test, y_test)\n",
    "    print(f\"Train accuracy: {w:0.2%}\")\n",
    "    print(f\"Test accuracy: {v:0.2%}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>\n",
      "[[29  5]\n",
      " [ 3 38]]\n",
      "Train accuracy: 96.64%\n",
      "Test accuracy: 89.33%\n",
      "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
      "[[32  2]\n",
      " [ 2 39]]\n",
      "Train accuracy: 100.00%\n",
      "Test accuracy: 94.67%\n",
      "<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
      "[[25  9]\n",
      " [11 30]]\n",
      "Train accuracy: 84.90%\n",
      "Test accuracy: 73.33%\n",
      "<class 'sklearn.svm.classes.SVC'>\n",
      "[[32  2]\n",
      " [ 3 38]]\n",
      "Train accuracy: 98.99%\n",
      "Test accuracy: 93.33%\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "[[29  5]\n",
      " [ 6 35]]\n",
      "Train accuracy: 100.00%\n",
      "Test accuracy: 85.33%\n",
      "<class 'sklearn.naive_bayes.GaussianNB'>\n",
      "[[25  9]\n",
      " [13 28]]\n",
      "Train accuracy: 66.78%\n",
      "Test accuracy: 70.67%\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "[[29  5]\n",
      " [ 6 35]]\n",
      "Train accuracy: 100.00%\n",
      "Test accuracy: 85.33%\n",
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "[[32  2]\n",
      " [ 3 38]]\n",
      "Train accuracy: 100.00%\n",
      "Test accuracy: 93.33%\n"
     ]
    }
   ],
   "source": [
    "accuracy(x_test, y_test, x_train, y_train, ann_model)\n",
    "accuracy(x_test, y_test, x_train, y_train, et_model)\n",
    "accuracy(x_test, y_test, x_train, y_train, av_model)\n",
    "accuracy(x_test, y_test, x_train, y_train, svm_model)\n",
    "accuracy(x_test, y_test, x_train, y_train, gb_model)\n",
    "accuracy(x_test, y_test, x_train, y_train, gnb_model)\n",
    "accuracy(x_test, y_test, x_train, y_train, rf_model)\n",
    "accuracy(x_test, y_test, x_train, y_train, knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_feature = et_model.feature_importances_\n",
    "av_feature = av_model.feature_importances_\n",
    "\n",
    "gb_feature = gb_model.feature_importances_\n",
    "rf_feature = rf_model.feature_importances_\n",
    "\n",
    "\n",
    "cols = feature_df.columns.tolist()\n",
    "# Create a dataframe with features\n",
    "feature_dataframe = pd.DataFrame( {'features': cols,\n",
    "                                   'Random Forest feature importances': rf_feature,\n",
    "                                   'AdaBoost feature importances': av_feature,\n",
    "                                   'Gradient Boost feature importances': gb_feature,\n",
    "                                   'Extra Trees  feature importances': et_feature,\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>Random Forest feature importances</th>\n",
       "      <th>AdaBoost feature importances</th>\n",
       "      <th>Gradient Boost feature importances</th>\n",
       "      <th>Extra Trees  feature importances</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M/F</td>\n",
       "      <td>0.044188</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.045143</td>\n",
       "      <td>0.065290</td>\n",
       "      <td>0.056261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.141147</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.125840</td>\n",
       "      <td>0.134734</td>\n",
       "      <td>0.125078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EDUC</td>\n",
       "      <td>0.133309</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.146221</td>\n",
       "      <td>0.173426</td>\n",
       "      <td>0.148450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SES</td>\n",
       "      <td>0.047740</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>0.061457</td>\n",
       "      <td>0.050951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>MMSE</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.049001</td>\n",
       "      <td>0.060849</td>\n",
       "      <td>0.046940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>eTIV</td>\n",
       "      <td>0.180350</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.177238</td>\n",
       "      <td>0.165462</td>\n",
       "      <td>0.183579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>nWBV</td>\n",
       "      <td>0.213182</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.226993</td>\n",
       "      <td>0.179376</td>\n",
       "      <td>0.211226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ASF</td>\n",
       "      <td>0.190342</td>\n",
       "      <td>0.183099</td>\n",
       "      <td>0.177209</td>\n",
       "      <td>0.159406</td>\n",
       "      <td>0.177514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features  Random Forest feature importances  AdaBoost feature importances  \\\n",
       "0      M/F                           0.044188                      0.070423   \n",
       "1      Age                           0.141147                      0.098592   \n",
       "2     EDUC                           0.133309                      0.140845   \n",
       "3      SES                           0.047740                      0.042254   \n",
       "4     MMSE                           0.049743                      0.028169   \n",
       "5     eTIV                           0.180350                      0.211268   \n",
       "6     nWBV                           0.213182                      0.225352   \n",
       "7      ASF                           0.190342                      0.183099   \n",
       "\n",
       "   Gradient Boost feature importances  Extra Trees  feature importances  \\\n",
       "0                            0.045143                          0.065290   \n",
       "1                            0.125840                          0.134734   \n",
       "2                            0.146221                          0.173426   \n",
       "3                            0.052355                          0.061457   \n",
       "4                            0.049001                          0.060849   \n",
       "5                            0.177238                          0.165462   \n",
       "6                            0.226993                          0.179376   \n",
       "7                            0.177209                          0.159406   \n",
       "\n",
       "       mean  \n",
       "0  0.056261  \n",
       "1  0.125078  \n",
       "2  0.148450  \n",
       "3  0.050951  \n",
       "4  0.046940  \n",
       "5  0.183579  \n",
       "6  0.211226  \n",
       "7  0.177514  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the new column that contains the average of the values.\n",
    "feature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\n",
    "feature_dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>SVM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>ANN</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>KNN</th>\n",
       "      <th>GNB</th>\n",
       "      <th>Real value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RandomForest  AdaBoost  GradientBoost  SVM  XGB  ANN  ExtraTrees  KNN  \\\n",
       "0              1         1              1    1    1    1           1    1   \n",
       "1              0         0              0    0    0    0           0    0   \n",
       "2              1         1              1    1    1    1           1    1   \n",
       "3              0         0              0    0    0    1           0    0   \n",
       "4              1         1              1    0    1    1           1    1   \n",
       "5              0         0              0    0    0    0           0    0   \n",
       "6              0         0              0    0    0    0           0    0   \n",
       "7              0         1              0    0    0    0           0    0   \n",
       "8              0         0              0    0    0    0           0    0   \n",
       "9              1         1              1    1    1    1           1    1   \n",
       "10             1         1              1    1    1    1           1    1   \n",
       "11             1         0              1    1    1    1           1    1   \n",
       "12             1         1              1    1    1    1           1    1   \n",
       "13             1         1              1    1    1    1           1    1   \n",
       "14             1         1              1    1    1    1           1    1   \n",
       "\n",
       "    GNB  Real value  \n",
       "0     1           1  \n",
       "1     0           0  \n",
       "2     1           1  \n",
       "3     0           0  \n",
       "4     1           0  \n",
       "5     0           0  \n",
       "6     0           0  \n",
       "7     1           0  \n",
       "8     0           0  \n",
       "9     0           1  \n",
       "10    1           1  \n",
       "11    0           1  \n",
       "12    1           1  \n",
       "13    0           1  \n",
       "14    1           1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {'RandomForest': rf_y_pred.ravel(),\n",
    "                                        'AdaBoost': av_y_pred.ravel(),\n",
    "                                        'GradientBoost': gb_y_pred.ravel(),\n",
    "                                        'SVM': svm_y_pred.ravel(),\n",
    "                                        'ANN': ann_y_pred.ravel(),\n",
    "                                        'ExtraTrees': et_y_pred.ravel(),\n",
    "                                        'KNN': knn_y_pred.ravel(),\n",
    "                                        'GNB': gnb_y_pred.ravel(),\n",
    "                                        'Real value': y_test                                \n",
    "                                        })\n",
    "base_predictions_train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Gradient Boost</th>\n",
       "      <th>Extra Trees</th>\n",
       "      <th>Xgboost</th>\n",
       "      <th>ANN</th>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <th>k Nearest Neigbour</th>\n",
       "      <th>Navies Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train Accuracy</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>84.90%</td>\n",
       "      <td>99.66%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>99.66%</td>\n",
       "      <td>95.64%</td>\n",
       "      <td>98.99%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>99.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test Accuracy</td>\n",
       "      <td>84.00%</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>88.00%</td>\n",
       "      <td>93.33%</td>\n",
       "      <td>82.67%</td>\n",
       "      <td>88.00%</td>\n",
       "      <td>93.33%</td>\n",
       "      <td>93.33%</td>\n",
       "      <td>82.67%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy Random Forest  AdaBoost Gradient Boost Extra Trees Xgboost  \\\n",
       "0  Train Accuracy        100.00%   84.90%         99.66%     100.00%  99.66%   \n",
       "1   Test Accuracy         84.00%   73.33%         88.00%      93.33%  82.67%   \n",
       "\n",
       "      ANN Support Vector Machine k Nearest Neigbour Navies Bayes  \n",
       "0  95.64%                 98.99%            100.00%       99.66%  \n",
       "1  88.00%                 93.33%             93.33%       82.67%  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc, f1_score\n",
    "def accuracy_dict(x_test, y_test, x_train, y_train, model):\n",
    "    test_accuracy = '{0:0.2%}'.format(model.score(x_train, y_train))\n",
    "    train_accuracy = '{0:0.2%}'.format(model.score(x_test, y_test))\n",
    "    acc_dict = {'0': test_accuracy , '1': train_accuracy}\n",
    "    return acc_dict\n",
    "\n",
    "acc_ann = accuracy_dict(x_test, y_test, x_train, y_train, ann_model)\n",
    "acc_et = accuracy_dict(x_test, y_test, x_train, y_train, et_model)\n",
    "acc_av =accuracy_dict(x_test, y_test, x_train, y_train, av_model)\n",
    "acc_svm = accuracy_dict(x_test, y_test, x_train, y_train, svm_model)\n",
    "acc_gb = accuracy_dict(x_test, y_test, x_train, y_train, gb_model)\n",
    "acc_gnb = accuracy_dict(x_test, y_test, x_train, y_train, gnb_model)\n",
    "acc_rf = accuracy_dict(x_test, y_test, x_train, y_train, rf_model)\n",
    "acc_knn = accuracy_dict(x_test, y_test, x_train, y_train, knn_model)\n",
    "accu = {'0': 'Train Accuracy', '1': 'Test Accuracy'}\n",
    "\n",
    "accuracy_dataframe = pd.DataFrame({'accuracy': accu,\n",
    "                                    'Random Forest ': acc_rf,\n",
    "                                    'AdaBoost': acc_av,\n",
    "                                    'Gradient Boost': acc_gb,\n",
    "                                    'Extra Trees': acc_et,\n",
    "                                    'Xgboost': acc_xgb,\n",
    "                                    'ANN': acc_ann,\n",
    "                                    'Support Vector Machine': acc_svm,\n",
    "                                    'k Nearest Neigbour': acc_knn,\n",
    "                                    'Navies Bayes': acc_xgb\n",
    "                                  })\n",
    "accuracy_dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_true, x_test, model, figsize=(10,10),):\n",
    "    y_pred = model.predict(x_test)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [298, 75]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a1ee69f3a17d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mann_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplot_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0met_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplot_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mav_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgb_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-300fae5b5a0c>\u001b[0m in \u001b[0;36mplot_cm\u001b[1;34m(y_true, x_test, model, figsize)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mcm_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcm_perc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcm_sum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [298, 75]"
     ]
    }
   ],
   "source": [
    "plot_cm(y_train, x_test, ann_model)\n",
    "plot_cm(y_train, x_test, et_model)\n",
    "plot_cm(y_train, x_test, av_model)\n",
    "plot_cm(y_train, x_test, svm_model)\n",
    "plot_cm(y_train, x_test, gb_model)\n",
    "plot_cm(y_train, x_test, gnb_model)\n",
    "plot_cm(y_train, x_test,  rf_model)\n",
    "plot_cm(y_train, x_test, knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
